{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 09:57:35.661648: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "comet_ml is installed but `COMET_API_KEY` is not set.\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v4.40. Import as `from transformers import GenerationMixin` instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/generation_tf_utils.py:24: FutureWarning: Importing `TFGenerationMixin` from `src/transformers/generation_tf_utils.py` is deprecated and will be removed in Transformers v4.40. Import as `from transformers import TFGenerationMixin` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import *\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the connection to the duckdb file\n",
    "duck_db = duckdb.connect('/Users/sheillapurwandiary/spurwand/BIPM/Semester2/2TWSM/OntologyProject/ontology/data/isrecon_AIS11.duckdb')\n",
    "#filtering the ontology for level_3  research method and data analysis method.\n",
    "ontology_df = duck_db.execute(\"\"\"\n",
    "SELECT * from main.ontology\n",
    "where level_3  in ('research method','data analysis method')\"\"\").df()\n",
    "\n",
    "#filtering the ontology for level_3  research method and data analysis method.\n",
    "\n",
    "synonyms_df = duck_db.execute(\"\"\"\n",
    "SELECT  DISTINCT  synonym\n",
    "FROM main.synonyms  s\n",
    "join main.ontology o\n",
    "on s.ent_id = o.ent_id \n",
    "where o.level_3  in ('research method', 'data analysis method')\"\"\").df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ent_id</th>\n",
       "      <th>definition</th>\n",
       "      <th>label</th>\n",
       "      <th>parent</th>\n",
       "      <th>level</th>\n",
       "      <th>related</th>\n",
       "      <th>level_1</th>\n",
       "      <th>level_2</th>\n",
       "      <th>level_3</th>\n",
       "      <th>level_4</th>\n",
       "      <th>level_5</th>\n",
       "      <th>level_6</th>\n",
       "      <th>level_7</th>\n",
       "      <th>level_8</th>\n",
       "      <th>level_9</th>\n",
       "      <th>level_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>research method</td>\n",
       "      <td>A research method is a systematic plan for con...</td>\n",
       "      <td></td>\n",
       "      <td>methodological entity</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>entity</td>\n",
       "      <td>methodological entity</td>\n",
       "      <td>research method</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>conceptual method</td>\n",
       "      <td>A conceptual method refers to a systematic app...</td>\n",
       "      <td>CONCEPTUAL_METHOD</td>\n",
       "      <td>research method</td>\n",
       "      <td>4.0</td>\n",
       "      <td>None</td>\n",
       "      <td>entity</td>\n",
       "      <td>methodological entity</td>\n",
       "      <td>research method</td>\n",
       "      <td>conceptual method</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>literature study</td>\n",
       "      <td>A literature study is a systematic and compreh...</td>\n",
       "      <td>CONCEPTUAL_METHOD</td>\n",
       "      <td>conceptual method</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>entity</td>\n",
       "      <td>methodological entity</td>\n",
       "      <td>research method</td>\n",
       "      <td>conceptual method</td>\n",
       "      <td>literature study</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>structured literature research</td>\n",
       "      <td>Structured literature research is a methodical...</td>\n",
       "      <td>CONCEPTUAL_METHOD</td>\n",
       "      <td>literature study</td>\n",
       "      <td>6.0</td>\n",
       "      <td>None</td>\n",
       "      <td>entity</td>\n",
       "      <td>methodological entity</td>\n",
       "      <td>research method</td>\n",
       "      <td>conceptual method</td>\n",
       "      <td>literature study</td>\n",
       "      <td>structured literature research</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>literature sample</td>\n",
       "      <td>A literature sample refers to a specific piece...</td>\n",
       "      <td>CONCEPTUAL_METHOD</td>\n",
       "      <td>structured literature research</td>\n",
       "      <td>7.0</td>\n",
       "      <td>None</td>\n",
       "      <td>entity</td>\n",
       "      <td>methodological entity</td>\n",
       "      <td>research method</td>\n",
       "      <td>conceptual method</td>\n",
       "      <td>literature study</td>\n",
       "      <td>structured literature research</td>\n",
       "      <td>literature sample</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>questionable research practice</td>\n",
       "      <td>Questionable research practice refers to the a...</td>\n",
       "      <td>ANALYSIS_METHOD</td>\n",
       "      <td>quantitative analysis</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>entity</td>\n",
       "      <td>methodological entity</td>\n",
       "      <td>data analysis method</td>\n",
       "      <td>quantitative analysis</td>\n",
       "      <td>questionable research practice</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>data dredging</td>\n",
       "      <td>Data dredging refers to the practice of conduc...</td>\n",
       "      <td>ANALYSIS_METHOD</td>\n",
       "      <td>questionable research practice</td>\n",
       "      <td>6.0</td>\n",
       "      <td>None</td>\n",
       "      <td>entity</td>\n",
       "      <td>methodological entity</td>\n",
       "      <td>data analysis method</td>\n",
       "      <td>quantitative analysis</td>\n",
       "      <td>questionable research practice</td>\n",
       "      <td>data dredging</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>p hacking</td>\n",
       "      <td>P hacking is the manipulative practice of rean...</td>\n",
       "      <td>ANALYSIS_METHOD</td>\n",
       "      <td>data dredging</td>\n",
       "      <td>7.0</td>\n",
       "      <td>None</td>\n",
       "      <td>entity</td>\n",
       "      <td>methodological entity</td>\n",
       "      <td>data analysis method</td>\n",
       "      <td>quantitative analysis</td>\n",
       "      <td>questionable research practice</td>\n",
       "      <td>data dredging</td>\n",
       "      <td>p hacking</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>HARKing</td>\n",
       "      <td>HARKing refers to the practice of formulating ...</td>\n",
       "      <td>ANALYSIS_METHOD</td>\n",
       "      <td>questionable research practice</td>\n",
       "      <td>6.0</td>\n",
       "      <td>None</td>\n",
       "      <td>entity</td>\n",
       "      <td>methodological entity</td>\n",
       "      <td>data analysis method</td>\n",
       "      <td>quantitative analysis</td>\n",
       "      <td>questionable research practice</td>\n",
       "      <td>HARKing</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>plagiarism</td>\n",
       "      <td>Plagiarism is the act of using another individ...</td>\n",
       "      <td>ANALYSIS_METHOD</td>\n",
       "      <td>questionable research practice</td>\n",
       "      <td>6.0</td>\n",
       "      <td>None</td>\n",
       "      <td>entity</td>\n",
       "      <td>methodological entity</td>\n",
       "      <td>data analysis method</td>\n",
       "      <td>quantitative analysis</td>\n",
       "      <td>questionable research practice</td>\n",
       "      <td>plagiarism</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>899 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             ent_id  \\\n",
       "0                   research method   \n",
       "1                 conceptual method   \n",
       "2                  literature study   \n",
       "3    structured literature research   \n",
       "4                 literature sample   \n",
       "..                              ...   \n",
       "894  questionable research practice   \n",
       "895                   data dredging   \n",
       "896                       p hacking   \n",
       "897                         HARKing   \n",
       "898                      plagiarism   \n",
       "\n",
       "                                            definition              label  \\\n",
       "0    A research method is a systematic plan for con...                      \n",
       "1    A conceptual method refers to a systematic app...  CONCEPTUAL_METHOD   \n",
       "2    A literature study is a systematic and compreh...  CONCEPTUAL_METHOD   \n",
       "3    Structured literature research is a methodical...  CONCEPTUAL_METHOD   \n",
       "4    A literature sample refers to a specific piece...  CONCEPTUAL_METHOD   \n",
       "..                                                 ...                ...   \n",
       "894  Questionable research practice refers to the a...    ANALYSIS_METHOD   \n",
       "895  Data dredging refers to the practice of conduc...    ANALYSIS_METHOD   \n",
       "896  P hacking is the manipulative practice of rean...    ANALYSIS_METHOD   \n",
       "897  HARKing refers to the practice of formulating ...    ANALYSIS_METHOD   \n",
       "898  Plagiarism is the act of using another individ...    ANALYSIS_METHOD   \n",
       "\n",
       "                             parent  level related level_1  \\\n",
       "0             methodological entity    3.0    None  entity   \n",
       "1                   research method    4.0    None  entity   \n",
       "2                 conceptual method    5.0    None  entity   \n",
       "3                  literature study    6.0    None  entity   \n",
       "4    structured literature research    7.0    None  entity   \n",
       "..                              ...    ...     ...     ...   \n",
       "894           quantitative analysis    5.0    None  entity   \n",
       "895  questionable research practice    6.0    None  entity   \n",
       "896                   data dredging    7.0    None  entity   \n",
       "897  questionable research practice    6.0    None  entity   \n",
       "898  questionable research practice    6.0    None  entity   \n",
       "\n",
       "                   level_2               level_3                level_4  \\\n",
       "0    methodological entity       research method                          \n",
       "1    methodological entity       research method      conceptual method   \n",
       "2    methodological entity       research method      conceptual method   \n",
       "3    methodological entity       research method      conceptual method   \n",
       "4    methodological entity       research method      conceptual method   \n",
       "..                     ...                   ...                    ...   \n",
       "894  methodological entity  data analysis method  quantitative analysis   \n",
       "895  methodological entity  data analysis method  quantitative analysis   \n",
       "896  methodological entity  data analysis method  quantitative analysis   \n",
       "897  methodological entity  data analysis method  quantitative analysis   \n",
       "898  methodological entity  data analysis method  quantitative analysis   \n",
       "\n",
       "                            level_5                         level_6  \\\n",
       "0                                                                     \n",
       "1                                                                     \n",
       "2                  literature study                                   \n",
       "3                  literature study  structured literature research   \n",
       "4                  literature study  structured literature research   \n",
       "..                              ...                             ...   \n",
       "894  questionable research practice                                   \n",
       "895  questionable research practice                   data dredging   \n",
       "896  questionable research practice                   data dredging   \n",
       "897  questionable research practice                         HARKing   \n",
       "898  questionable research practice                      plagiarism   \n",
       "\n",
       "               level_7 level_8 level_9 level_10  \n",
       "0                                                \n",
       "1                                                \n",
       "2                                                \n",
       "3                                                \n",
       "4    literature sample                           \n",
       "..                 ...     ...     ...      ...  \n",
       "894                                              \n",
       "895                                              \n",
       "896          p hacking                           \n",
       "897                                              \n",
       "898                                              \n",
       "\n",
       "[899 rows x 16 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ontology_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>synonym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>atlasti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>atlas.ti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QDA Miner Lite tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>video coded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>coded all statement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31765</th>\n",
       "      <td>cohort polling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31766</th>\n",
       "      <td>panel survey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31767</th>\n",
       "      <td>skin conductance level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31768</th>\n",
       "      <td>skin conductance response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31769</th>\n",
       "      <td>skin conductance testing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31770 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         synonym\n",
       "0                        atlasti\n",
       "1                       atlas.ti\n",
       "2            QDA Miner Lite tool\n",
       "3                    video coded\n",
       "4            coded all statement\n",
       "...                          ...\n",
       "31765             cohort polling\n",
       "31766               panel survey\n",
       "31767     skin conductance level\n",
       "31768  skin conductance response\n",
       "31769   skin conductance testing\n",
       "\n",
       "[31770 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonyms_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before  (31770, 1)\n",
      "After:  (31770, 1)\n",
      "Before  (899, 1)\n",
      "After:  (220, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>atlasti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>atlas.ti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QDA Miner Lite tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>video coded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>coded all statement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31765</th>\n",
       "      <td>cohort polling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31766</th>\n",
       "      <td>panel survey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31767</th>\n",
       "      <td>skin conductance level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31768</th>\n",
       "      <td>skin conductance response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31769</th>\n",
       "      <td>skin conductance testing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31770 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            text\n",
       "0                        atlasti\n",
       "1                       atlas.ti\n",
       "2            QDA Miner Lite tool\n",
       "3                    video coded\n",
       "4            coded all statement\n",
       "...                          ...\n",
       "31765             cohort polling\n",
       "31766               panel survey\n",
       "31767     skin conductance level\n",
       "31768  skin conductance response\n",
       "31769   skin conductance testing\n",
       "\n",
       "[31770 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Before ', synonyms_df.shape)\n",
    "synonyms_df.drop_duplicates(inplace=True)\n",
    "print('After: ', synonyms_df.shape)\n",
    "\n",
    "#resetting index to avoid issues\n",
    "synonyms_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#  Creating a copy of the ontology_df and selecting the 'parent' column\n",
    "data_ontology = ontology_df.copy()\n",
    "data_ontology = data_ontology[['parent']]\n",
    "data_ontology['text'] = data_ontology['parent']\n",
    "del(data_ontology['parent'])\n",
    "\n",
    "# Creating a copy of the synonyms_df and selecting the 'synonym' column\n",
    "data_synonyms = synonyms_df.copy()\n",
    "data_synonyms['text'] = data_synonyms['synonym']\n",
    "del(data_synonyms['synonym'])\n",
    "\n",
    "print('Before ', data_ontology.shape)\n",
    "data_ontology.drop_duplicates(inplace=True)\n",
    "print('After: ', data_ontology.shape)\n",
    "\n",
    "#resetting index to avoid issues\n",
    "data_ontology.reset_index(drop=True, inplace=True)\n",
    "data_synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>methodological entity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>research method</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>conceptual method</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>literature study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>structured literature research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>statistical test assumption</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>homoskedasticity test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>odds ratio homogeneity test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>questionable research practice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>data dredging</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               text\n",
       "0             methodological entity\n",
       "1                   research method\n",
       "2                 conceptual method\n",
       "3                  literature study\n",
       "4    structured literature research\n",
       "..                              ...\n",
       "215     statistical test assumption\n",
       "216           homoskedasticity test\n",
       "217     odds ratio homogeneity test\n",
       "218  questionable research practice\n",
       "219                   data dredging\n",
       "\n",
       "[220 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_synonyms_list = data_synonyms[\"text\"].to_list()\n",
    "data_ontology_list = data_ontology[\"text\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at /Users/sheillapurwandiary/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/vocab.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /Users/sheillapurwandiary/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/tokenizer_config.json\n",
      "loading file tokenizer.json from cache at /Users/sheillapurwandiary/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/tokenizer.json\n",
      "loading configuration file config.json from cache at /Users/sheillapurwandiary/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.39.3\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /Users/sheillapurwandiary/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.39.3\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /Users/sheillapurwandiary/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/12040accade4e8a0f71eabdb258fecc2e7e948be/model.safetensors\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of DistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load the DistilBERT tokenizer and model\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(term):\n",
    "   # Tokenize the text\n",
    "    tokens = tokenizer(term, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    # Generate embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "    embeddings = outputs.last_hidden_state[:, 0, :].numpy()  # Take the embeddings from the CLS token\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonym_embeddings = {term: get_embeddings(term)[0] for term in data_synonyms_list}\n",
    "ontology_embeddings = {term: get_embeddings(term)[0] for term in data_ontology_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_synonym(new_term):\n",
    "    \"\"\"\n",
    "    Compare a new_term with the list of synonyms and ontology terms stored using cosine similarity.\n",
    "\n",
    "    Args:\n",
    "        new_term: A single term to be compared.\n",
    "\n",
    "    Returns:\n",
    "        A string indicating if the term is a synonym to any word in the list and the score, or if no synonym was found.\n",
    "    \"\"\"\n",
    "    new_term_embds = get_embeddings([new_term])\n",
    "    similarity_scores = {}\n",
    "    overall_embeddings = {**synonym_embeddings, **ontology_embeddings}\n",
    "    for term, embedding in overall_embeddings.items():\n",
    "        similarity = cosine_similarity(new_term_embds[new_term].reshape(1, -1), embedding.reshape(1, -1))[0][0]\n",
    "        similarity_scores[term] = similarity\n",
    "    sorted_similarity_scores = dict(sorted(similarity_scores.items(), key=lambda item: item[1], reverse=True))\n",
    "    if sorted_similarity_scores and list(sorted_similarity_scores.values())[0] > 0.7:\n",
    "        top_synonym = list(sorted_similarity_scores.keys())[0]\n",
    "        return f\"is synonym to {top_synonym} with a similarity score of {list(sorted_similarity_scores.values())[0]}\"\n",
    "    else:\n",
    "        return \"No close synonyms found in the list.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m new_term \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapple\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mis_synonym\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_term\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 15\u001b[0m, in \u001b[0;36mis_synonym\u001b[0;34m(new_term)\u001b[0m\n\u001b[1;32m     13\u001b[0m overall_embeddings \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msynonym_embeddings, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39montology_embeddings}\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m term, embedding \u001b[38;5;129;01min\u001b[39;00m overall_embeddings\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 15\u001b[0m     similarity \u001b[38;5;241m=\u001b[39m cosine_similarity(\u001b[43mnew_term_embds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnew_term\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), embedding\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     16\u001b[0m     similarity_scores[term] \u001b[38;5;241m=\u001b[39m similarity\n\u001b[1;32m     17\u001b[0m sorted_similarity_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28msorted\u001b[39m(similarity_scores\u001b[38;5;241m.\u001b[39mitems(), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m item: item[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "new_term = \"apple\"\n",
    "is_synonym(new_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_synonym(new_term):\n",
    "    \"\"\"\n",
    "    Compare a new_term with the list of synonyms and ontology terms stored using cosine similarity.\n",
    "\n",
    "    Args:\n",
    "        new_term (str): a single term to be compared\n",
    "    \n",
    "    Returns:\n",
    "        str: A string that tells if the term is a synonym to another word and the score, or if there was no synonym in the list.\n",
    "    \"\"\"\n",
    "    if not isinstance(new_term, str):\n",
    "        raise ValueError(\"new_term should be a string\")\n",
    "    \n",
    "    # Get embeddings for the new term\n",
    "    new_term_embd = get_embeddings(new_term)[0]\n",
    "    \n",
    "    similarity_scores = {}\n",
    "    overall_embeddings = {**synonym_embeddings, **ontology_embeddings}\n",
    "    # Calculate cosine similarity between the new term and each stored term\n",
    "    for term, embedding in overall_embeddings.items():\n",
    "        similarity = cosine_similarity(new_term_embd.reshape(1, -1), embedding.reshape(1, -1))[0][0]\n",
    "        similarity_scores[term] = similarity\n",
    "    \n",
    "    # Sort similarity scores in descending order\n",
    "    sorted_similarity_scores = sorted(similarity_scores.items(), key=lambda item: item[1], reverse=True)\n",
    "    \n",
    "    # Check if the highest similarity score is above the threshold (0.7)\n",
    "    if sorted_similarity_scores and sorted_similarity_scores[0][1] > 0.7:\n",
    "        top_synonym, top_score = sorted_similarity_scores[0]\n",
    "        return f\"{new_term} is a synonym to {top_synonym} with a similarity score of {top_score:.2f}\"\n",
    "    else:\n",
    "        return f\"{new_term} is not a close synonym to any term in the list.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apple is a synonym to eyetracker with a similarity score of 0.97'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_term = \"apple\"\n",
    "is_synonym(new_term)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
