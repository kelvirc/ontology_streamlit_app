{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-24 20:50:31.928683: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "comet_ml is installed but `COMET_API_KEY` is not set.\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v4.40. Import as `from transformers import GenerationMixin` instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/generation_tf_utils.py:24: FutureWarning: Importing `TFGenerationMixin` from `src/transformers/generation_tf_utils.py` is deprecated and will be removed in Transformers v4.40. Import as `from transformers import TFGenerationMixin` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import *\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'your_database.duckdb' with your actual database file path\n",
    "con = duckdb.connect(database='/Users/sheillapurwandiary/spurwand/BIPM/Semester2/2TWSM/OntologyProject/ontology/Duckdb/isrecon_AIS11.duckdb')\n",
    "\n",
    "\n",
    "# Replace 'your_table' with your actual table name\n",
    "ontology_df = con.execute(\"\"\"\n",
    "SELECT * from main.ontology\n",
    "where level_3  in ('research method','data analysis method')\"\"\").df()\n",
    "\n",
    "#filtering the ontology for level_3  research method and data analysis method.\n",
    "\n",
    "synonyms_df = con.execute(\"\"\"\n",
    "SELECT  DISTINCT  synonym\n",
    "FROM synonyms  s\n",
    "join ontology o\n",
    "on s.ent_id = o.ent_id \n",
    "where o.level_3  in ('research method', 'data analysis method')\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31770 entries, 0 to 31769\n",
      "Data columns (total 1 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   synonym  31770 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 248.3+ KB\n"
     ]
    }
   ],
   "source": [
    "synonyms_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ent_id</th>\n",
       "      <th>definition</th>\n",
       "      <th>label</th>\n",
       "      <th>parent</th>\n",
       "      <th>level</th>\n",
       "      <th>related</th>\n",
       "      <th>level_1</th>\n",
       "      <th>level_2</th>\n",
       "      <th>level_3</th>\n",
       "      <th>level_4</th>\n",
       "      <th>level_5</th>\n",
       "      <th>level_6</th>\n",
       "      <th>level_7</th>\n",
       "      <th>level_8</th>\n",
       "      <th>level_9</th>\n",
       "      <th>level_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>research method</td>\n",
       "      <td>A research method is a systematic plan for con...</td>\n",
       "      <td></td>\n",
       "      <td>methodological entity</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>entity</td>\n",
       "      <td>methodological entity</td>\n",
       "      <td>research method</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>conceptual method</td>\n",
       "      <td>A conceptual method refers to a systematic app...</td>\n",
       "      <td>CONCEPTUAL_METHOD</td>\n",
       "      <td>research method</td>\n",
       "      <td>4.0</td>\n",
       "      <td>None</td>\n",
       "      <td>entity</td>\n",
       "      <td>methodological entity</td>\n",
       "      <td>research method</td>\n",
       "      <td>conceptual method</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>literature study</td>\n",
       "      <td>A literature study is a systematic and compreh...</td>\n",
       "      <td>CONCEPTUAL_METHOD</td>\n",
       "      <td>conceptual method</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>entity</td>\n",
       "      <td>methodological entity</td>\n",
       "      <td>research method</td>\n",
       "      <td>conceptual method</td>\n",
       "      <td>literature study</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>structured literature research</td>\n",
       "      <td>Structured literature research is a methodical...</td>\n",
       "      <td>CONCEPTUAL_METHOD</td>\n",
       "      <td>literature study</td>\n",
       "      <td>6.0</td>\n",
       "      <td>None</td>\n",
       "      <td>entity</td>\n",
       "      <td>methodological entity</td>\n",
       "      <td>research method</td>\n",
       "      <td>conceptual method</td>\n",
       "      <td>literature study</td>\n",
       "      <td>structured literature research</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>literature sample</td>\n",
       "      <td>A literature sample refers to a specific piece...</td>\n",
       "      <td>CONCEPTUAL_METHOD</td>\n",
       "      <td>structured literature research</td>\n",
       "      <td>7.0</td>\n",
       "      <td>None</td>\n",
       "      <td>entity</td>\n",
       "      <td>methodological entity</td>\n",
       "      <td>research method</td>\n",
       "      <td>conceptual method</td>\n",
       "      <td>literature study</td>\n",
       "      <td>structured literature research</td>\n",
       "      <td>literature sample</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>questionable research practice</td>\n",
       "      <td>Questionable research practice refers to the a...</td>\n",
       "      <td>ANALYSIS_METHOD</td>\n",
       "      <td>quantitative analysis</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>entity</td>\n",
       "      <td>methodological entity</td>\n",
       "      <td>data analysis method</td>\n",
       "      <td>quantitative analysis</td>\n",
       "      <td>questionable research practice</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>data dredging</td>\n",
       "      <td>Data dredging refers to the practice of conduc...</td>\n",
       "      <td>ANALYSIS_METHOD</td>\n",
       "      <td>questionable research practice</td>\n",
       "      <td>6.0</td>\n",
       "      <td>None</td>\n",
       "      <td>entity</td>\n",
       "      <td>methodological entity</td>\n",
       "      <td>data analysis method</td>\n",
       "      <td>quantitative analysis</td>\n",
       "      <td>questionable research practice</td>\n",
       "      <td>data dredging</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>p hacking</td>\n",
       "      <td>P hacking is the manipulative practice of rean...</td>\n",
       "      <td>ANALYSIS_METHOD</td>\n",
       "      <td>data dredging</td>\n",
       "      <td>7.0</td>\n",
       "      <td>None</td>\n",
       "      <td>entity</td>\n",
       "      <td>methodological entity</td>\n",
       "      <td>data analysis method</td>\n",
       "      <td>quantitative analysis</td>\n",
       "      <td>questionable research practice</td>\n",
       "      <td>data dredging</td>\n",
       "      <td>p hacking</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>HARKing</td>\n",
       "      <td>HARKing refers to the practice of formulating ...</td>\n",
       "      <td>ANALYSIS_METHOD</td>\n",
       "      <td>questionable research practice</td>\n",
       "      <td>6.0</td>\n",
       "      <td>None</td>\n",
       "      <td>entity</td>\n",
       "      <td>methodological entity</td>\n",
       "      <td>data analysis method</td>\n",
       "      <td>quantitative analysis</td>\n",
       "      <td>questionable research practice</td>\n",
       "      <td>HARKing</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>plagiarism</td>\n",
       "      <td>Plagiarism is the act of using another individ...</td>\n",
       "      <td>ANALYSIS_METHOD</td>\n",
       "      <td>questionable research practice</td>\n",
       "      <td>6.0</td>\n",
       "      <td>None</td>\n",
       "      <td>entity</td>\n",
       "      <td>methodological entity</td>\n",
       "      <td>data analysis method</td>\n",
       "      <td>quantitative analysis</td>\n",
       "      <td>questionable research practice</td>\n",
       "      <td>plagiarism</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>899 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             ent_id  \\\n",
       "0                   research method   \n",
       "1                 conceptual method   \n",
       "2                  literature study   \n",
       "3    structured literature research   \n",
       "4                 literature sample   \n",
       "..                              ...   \n",
       "894  questionable research practice   \n",
       "895                   data dredging   \n",
       "896                       p hacking   \n",
       "897                         HARKing   \n",
       "898                      plagiarism   \n",
       "\n",
       "                                            definition              label  \\\n",
       "0    A research method is a systematic plan for con...                      \n",
       "1    A conceptual method refers to a systematic app...  CONCEPTUAL_METHOD   \n",
       "2    A literature study is a systematic and compreh...  CONCEPTUAL_METHOD   \n",
       "3    Structured literature research is a methodical...  CONCEPTUAL_METHOD   \n",
       "4    A literature sample refers to a specific piece...  CONCEPTUAL_METHOD   \n",
       "..                                                 ...                ...   \n",
       "894  Questionable research practice refers to the a...    ANALYSIS_METHOD   \n",
       "895  Data dredging refers to the practice of conduc...    ANALYSIS_METHOD   \n",
       "896  P hacking is the manipulative practice of rean...    ANALYSIS_METHOD   \n",
       "897  HARKing refers to the practice of formulating ...    ANALYSIS_METHOD   \n",
       "898  Plagiarism is the act of using another individ...    ANALYSIS_METHOD   \n",
       "\n",
       "                             parent  level related level_1  \\\n",
       "0             methodological entity    3.0    None  entity   \n",
       "1                   research method    4.0    None  entity   \n",
       "2                 conceptual method    5.0    None  entity   \n",
       "3                  literature study    6.0    None  entity   \n",
       "4    structured literature research    7.0    None  entity   \n",
       "..                              ...    ...     ...     ...   \n",
       "894           quantitative analysis    5.0    None  entity   \n",
       "895  questionable research practice    6.0    None  entity   \n",
       "896                   data dredging    7.0    None  entity   \n",
       "897  questionable research practice    6.0    None  entity   \n",
       "898  questionable research practice    6.0    None  entity   \n",
       "\n",
       "                   level_2               level_3                level_4  \\\n",
       "0    methodological entity       research method                          \n",
       "1    methodological entity       research method      conceptual method   \n",
       "2    methodological entity       research method      conceptual method   \n",
       "3    methodological entity       research method      conceptual method   \n",
       "4    methodological entity       research method      conceptual method   \n",
       "..                     ...                   ...                    ...   \n",
       "894  methodological entity  data analysis method  quantitative analysis   \n",
       "895  methodological entity  data analysis method  quantitative analysis   \n",
       "896  methodological entity  data analysis method  quantitative analysis   \n",
       "897  methodological entity  data analysis method  quantitative analysis   \n",
       "898  methodological entity  data analysis method  quantitative analysis   \n",
       "\n",
       "                            level_5                         level_6  \\\n",
       "0                                                                     \n",
       "1                                                                     \n",
       "2                  literature study                                   \n",
       "3                  literature study  structured literature research   \n",
       "4                  literature study  structured literature research   \n",
       "..                              ...                             ...   \n",
       "894  questionable research practice                                   \n",
       "895  questionable research practice                   data dredging   \n",
       "896  questionable research practice                   data dredging   \n",
       "897  questionable research practice                         HARKing   \n",
       "898  questionable research practice                      plagiarism   \n",
       "\n",
       "               level_7 level_8 level_9 level_10  \n",
       "0                                                \n",
       "1                                                \n",
       "2                                                \n",
       "3                                                \n",
       "4    literature sample                           \n",
       "..                 ...     ...     ...      ...  \n",
       "894                                              \n",
       "895                                              \n",
       "896          p hacking                           \n",
       "897                                              \n",
       "898                                              \n",
       "\n",
       "[899 rows x 16 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ontology_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>synonym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QDA Miner software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QDA Miner Lite software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>code each interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>coded each statement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>annotate all interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31765</th>\n",
       "      <td>galvanic skin conductance activity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31766</th>\n",
       "      <td>tonic skin conductance response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31767</th>\n",
       "      <td>skin conductance evaluation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31768</th>\n",
       "      <td>telemonitoring tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31769</th>\n",
       "      <td>quantified self</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31770 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  synonym\n",
       "0                      QDA Miner software\n",
       "1                 QDA Miner Lite software\n",
       "2                     code each interview\n",
       "3                    coded each statement\n",
       "4                  annotate all interview\n",
       "...                                   ...\n",
       "31765  galvanic skin conductance activity\n",
       "31766     tonic skin conductance response\n",
       "31767         skin conductance evaluation\n",
       "31768                 telemonitoring tool\n",
       "31769                     quantified self\n",
       "\n",
       "[31770 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonyms_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before  (31770, 1)\n",
      "After:  (31770, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Before ', synonyms_df.shape)\n",
    "synonyms_df.drop_duplicates(inplace=True)\n",
    "print('After: ', synonyms_df.shape)\n",
    "\n",
    "#resetting index to avoid issues\n",
    "synonyms_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a copy of the ontology_df and selecting the 'parent' column\n",
    "data_ontology = ontology_df.copy()\n",
    "data_ontology = data_ontology[['parent']]\n",
    "data_ontology['text'] = data_ontology['parent']\n",
    "del(data_ontology['parent'])\n",
    "\n",
    "# Creating a copy of the synonyms_df and selecting the 'synonym' column\n",
    "data_synonyms = synonyms_df.copy()\n",
    "data_synonyms['text'] = data_synonyms['synonym']\n",
    "del(data_synonyms['synonym'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before  (899, 1)\n",
      "After:  (220, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Before ', data_ontology.shape)\n",
    "data_ontology.drop_duplicates(inplace=True)\n",
    "print('After: ', data_ontology.shape)\n",
    "\n",
    "#resetting index to avoid issues\n",
    "data_ontology.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QDA Miner software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QDA Miner Lite software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>code each interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>coded each statement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>annotate all interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31765</th>\n",
       "      <td>galvanic skin conductance activity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31766</th>\n",
       "      <td>tonic skin conductance response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31767</th>\n",
       "      <td>skin conductance evaluation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31768</th>\n",
       "      <td>telemonitoring tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31769</th>\n",
       "      <td>quantified self</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31770 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     text\n",
       "0                      QDA Miner software\n",
       "1                 QDA Miner Lite software\n",
       "2                     code each interview\n",
       "3                    coded each statement\n",
       "4                  annotate all interview\n",
       "...                                   ...\n",
       "31765  galvanic skin conductance activity\n",
       "31766     tonic skin conductance response\n",
       "31767         skin conductance evaluation\n",
       "31768                 telemonitoring tool\n",
       "31769                     quantified self\n",
       "\n",
       "[31770 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_synonyms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>methodological entity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>research method</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>conceptual method</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>literature study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>structured literature research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>statistical test assumption</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>homoskedasticity test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>odds ratio homogeneity test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>questionable research practice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>data dredging</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               text\n",
       "0             methodological entity\n",
       "1                   research method\n",
       "2                 conceptual method\n",
       "3                  literature study\n",
       "4    structured literature research\n",
       "..                              ...\n",
       "215     statistical test assumption\n",
       "216           homoskedasticity test\n",
       "217     odds ratio homogeneity test\n",
       "218  questionable research practice\n",
       "219                   data dredging\n",
       "\n",
       "[220 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique entries in data_synonyms: 31770\n",
      "Unique entries in data_ontology: 220\n",
      "Common entries between data_synonyms and data_ontology: 4\n",
      "Common entries: {'research method', 'quantitative analysis', 'archival database', 'qualitative analysis'}\n"
     ]
    }
   ],
   "source": [
    "# Unique entries in data_synonyms\n",
    "unique_synonyms = data_synonyms['text'].unique()\n",
    "print(f\"Unique entries in data_synonyms: {len(unique_synonyms)}\")\n",
    "\n",
    "# Unique entries in data_ontology\n",
    "unique_ontology = data_ontology['text'].unique()\n",
    "print(f\"Unique entries in data_ontology: {len(unique_ontology)}\")\n",
    "\n",
    "# Find common entries between the two dataframes\n",
    "common_entries = set(unique_synonyms).intersection(set(unique_ontology))\n",
    "print(f\"Common entries between data_synonyms and data_ontology: {len(common_entries)}\")\n",
    "print(f\"Common entries: {common_entries}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_synonyms_list = data_synonyms[\"text\"].to_list()\n",
    "data_ontology_list = data_ontology[\"text\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['QDA Miner software',\n",
       " 'QDA Miner Lite software',\n",
       " 'code each interview',\n",
       " 'coded each statement',\n",
       " 'annotate all interview',\n",
       " 'labeled each statement',\n",
       " 'label each statement',\n",
       " 'axial coding',\n",
       " 'annotated the interview',\n",
       " 'annotated each interview',\n",
       " 'constant comparative method',\n",
       " 'narrative approach',\n",
       " 'quantitative article',\n",
       " 'quantitative paper',\n",
       " 'SAS enterprise miner',\n",
       " 'R software environment',\n",
       " 'R implementation',\n",
       " 'CRAN',\n",
       " 'predictive modeling',\n",
       " 'predictive analytics',\n",
       " 'ResNet',\n",
       " 'GPT 2',\n",
       " 'generative pre trained transformer 2',\n",
       " 'classification algorithm',\n",
       " 'k nearest neighbor',\n",
       " 'naive bayes',\n",
       " 'classification and regression tree',\n",
       " 'CART tree',\n",
       " 'C4 5',\n",
       " 'metalearning',\n",
       " 'ensemble method',\n",
       " 'booting algorithm',\n",
       " 'clustering study',\n",
       " 'clustering research',\n",
       " 'clustering analysis',\n",
       " 'density based spatial clustering of applications with noise',\n",
       " 'self supervised learning',\n",
       " 'cross industry standard process for data mining',\n",
       " 'CRISP DM',\n",
       " 'face recognition',\n",
       " 'Face ID',\n",
       " 'face recognition tool',\n",
       " 'text analytics',\n",
       " 'LDA investigation',\n",
       " 'topic modeling algorithm',\n",
       " 'topic modeling methodology',\n",
       " 'topic modeling research',\n",
       " 'topic modeling',\n",
       " 'part of speech tag',\n",
       " 'conversational agent',\n",
       " 'chat bot',\n",
       " 'spatial data analysis',\n",
       " 'spatial stratified heterogeneity',\n",
       " 'geo analytics',\n",
       " 'extreme value methodology',\n",
       " 'extreme value method',\n",
       " 'extreme value investigation',\n",
       " 'mean imputation',\n",
       " 'MICE',\n",
       " 'data normalization',\n",
       " 'structured probabilistic model',\n",
       " 'strong true score theory',\n",
       " 'Amos',\n",
       " 'SEM system',\n",
       " 'PLSc',\n",
       " 'power of test',\n",
       " 'multi attribute compositional modeling',\n",
       " 'stated preference technique',\n",
       " 'ablation test',\n",
       " 'time series',\n",
       " 'GARCH algorithm',\n",
       " 'GARCH study',\n",
       " 'ARIMA study',\n",
       " 'Box–Jenkins model',\n",
       " 'Box–Jenkins method',\n",
       " 'Box–Jenkins methodology',\n",
       " 'Box–Jenkins algorithm',\n",
       " 'ADF test',\n",
       " 'augmented Dickey Fuller',\n",
       " 'potential outcomes methodology',\n",
       " 'potential outcome description',\n",
       " 'potential outcome model',\n",
       " 'potential outcome algorithm',\n",
       " 'potential outcomes study',\n",
       " 'potential outcome investigation',\n",
       " 'instrumental variable technique',\n",
       " 'instrumental variable study',\n",
       " 'econometric study',\n",
       " 'econometric description',\n",
       " 'applied econometrics',\n",
       " 'econometric research',\n",
       " 'Cox model',\n",
       " 'first passage time',\n",
       " 'cumulative sum research',\n",
       " 'CUSUM methodology',\n",
       " 'cumulative sum technique',\n",
       " 'CUSUM description',\n",
       " 'CUSUM investigation',\n",
       " 'multi armed bandit problem',\n",
       " 'data projection',\n",
       " 'nonnegative matrix approximation',\n",
       " 'nonnegative matrix factorization',\n",
       " 'non negative matrix approximation',\n",
       " 'least trimmed square',\n",
       " 'multinomial logistic regression for analysis of dichotomous dependent variable',\n",
       " 'Ramsey regression equation specification error (RESET) tested',\n",
       " 'testing a hypothesis',\n",
       " 'testing statistical hypothesis',\n",
       " 'testing the hypothesis',\n",
       " 'statistic these hypothesis',\n",
       " 'statistic hypothesis',\n",
       " 'null hypothesis statistic',\n",
       " 't test for dependent means',\n",
       " 'paired t test',\n",
       " 'chi square test',\n",
       " 'chisquare test',\n",
       " 'χ 2 test',\n",
       " \"Pearson's chi 2 test\",\n",
       " 'chisquare test for independence',\n",
       " 'Chi2 test for independence',\n",
       " \"Yate's correction for continuity\",\n",
       " 'χ2 test for goodness of fit',\n",
       " 'χ2 goodness of fit test',\n",
       " 'rmANOVA',\n",
       " 'rmanova',\n",
       " 'Mann Whitney U testing',\n",
       " 'Mann Whitney testing',\n",
       " 'Mann Whitney Wilcoxon',\n",
       " 'post hoc analysis',\n",
       " \"Tukey's honestly significant difference\",\n",
       " 'Tukey HDS',\n",
       " 'Holm–Bonferroni investigation',\n",
       " 'Holm–Bonferroni algorithm',\n",
       " 'Benjamini–Hochberg research',\n",
       " 'Benjamini–Hochberg analysis',\n",
       " 'Benjamini–Hochberg technique',\n",
       " 'tested of independence between variables',\n",
       " 'Chi2 statistic for independence',\n",
       " \"Fisher 's statistic\",\n",
       " \"Fisher's test\",\n",
       " \"Barnard 's exact statistic\",\n",
       " 'Cochran Mantel Haenszel test for repeated tests of independence',\n",
       " 'CHM tested',\n",
       " 'plagiarise',\n",
       " 'information analysis algorithm',\n",
       " 'data analysis',\n",
       " 'computer based interaction analysis software',\n",
       " 'computer aided qualitative data analysis',\n",
       " 'computer enabled interaction analysis',\n",
       " 'computer assisted qualitative data analysis system',\n",
       " 'computer mediated interaction analysis',\n",
       " 'computer mediate content analysis system',\n",
       " 'computer mediated discursive analysis tool',\n",
       " 'computer enabled metaphor analysis',\n",
       " 'computer assisted conversation analysis software',\n",
       " 'computer supported text analysis tool',\n",
       " 'computer enabled discourse analysis software',\n",
       " 'computer supported textual analysis software',\n",
       " 'computer mediated conversation analysis software',\n",
       " 'computer enabled transcription analysis system',\n",
       " 'computer enabled discourse analysis tool',\n",
       " 'computer supported qualitative data analysis',\n",
       " 'computer enabled conversation analysis system',\n",
       " 'computer supported thematic analysis system',\n",
       " 'computer enabled text analysis tool',\n",
       " 'computer mediated semiotic analysis',\n",
       " 'computer assisted metaphor analysis tool',\n",
       " 'computer mediated textual analysis software',\n",
       " 'computer mediated conversation analysis system',\n",
       " 'computer mediate rhetorical analysis tool',\n",
       " 'computer assisted metaphor analysis',\n",
       " 'computer aided document analysis',\n",
       " 'computer enabled conversation analysis tool',\n",
       " 'computer mediate interaction analysis',\n",
       " 'computer mediated conversation analysis',\n",
       " 'computer mediated rhetorical analysis tool',\n",
       " 'computer mediate interaction analysis system',\n",
       " 'computer enabled interaction analysis tool',\n",
       " 'computer assisted discourse analysis software',\n",
       " 'computer mediate metaphor analysis',\n",
       " 'computer aided corpus analysis software',\n",
       " 'computer based thematic analysis software',\n",
       " 'computer aided thematic analysis',\n",
       " 'computer mediated text analysis software',\n",
       " 'computer assisted text analysis system',\n",
       " 'computer based conversation analysis tool',\n",
       " 'computer mediate document analysis software',\n",
       " 'computer based metaphor analysis',\n",
       " 'computer supported text analysis system',\n",
       " 'computer mediated qualitative data analysis system',\n",
       " 'computer supported metaphor analysis software',\n",
       " 'computer mediated rhetorical analysis system',\n",
       " 'computer supported conversation analysis system',\n",
       " 'computer assisted corpus analysis',\n",
       " 'computer based thematic analysis',\n",
       " 'computer based conversation analysis',\n",
       " 'computer aided text analysis',\n",
       " 'computer aided qualitative data analysis tool',\n",
       " 'computer mediate qualitative data analysis tool',\n",
       " 'computer supported discursive analysis system',\n",
       " 'computer based documentary analysis tool',\n",
       " 'computer assisted interaction analysis system',\n",
       " 'computer supported documentary analysis',\n",
       " 'critical corpus analysis',\n",
       " 'transcript analysis',\n",
       " 'critical transcript analysis',\n",
       " 'qualitative conversation analysis',\n",
       " 'textual analysis',\n",
       " 'support vector machine classifier',\n",
       " 'gradient boosting classification',\n",
       " 'outlier detection',\n",
       " 'deviation detection',\n",
       " 'semi supervised technique',\n",
       " 'semi supervised algorithm',\n",
       " 'semi supervised research',\n",
       " 'multimodal opinion mining',\n",
       " 'spatial regression analysis',\n",
       " 'spatial regression method',\n",
       " 'PLS PM',\n",
       " 'partial least squares for structural equation model',\n",
       " 'ARMA analysis',\n",
       " 'partial least squares',\n",
       " 'PLS correlation',\n",
       " 'orthogonal projections to latent structures',\n",
       " 'hierarchical linear model',\n",
       " 'nested data modeling',\n",
       " 'score test',\n",
       " \"Yuen Welch's t statistic\",\n",
       " 'Dunn comparison test',\n",
       " \"McNemar 's test\",\n",
       " 'Cochran Armitage test',\n",
       " 'homoskedasticity tested',\n",
       " 'Levene testing',\n",
       " \"Levene 's testing\",\n",
       " 'library review',\n",
       " 'review article',\n",
       " 'library study',\n",
       " 'literature review',\n",
       " 'research review',\n",
       " 'bibliographical review',\n",
       " 'of the paper',\n",
       " 'ABI / Inform',\n",
       " 'Springer Link',\n",
       " 'journal list',\n",
       " 'basket of eight journal',\n",
       " 'author bibliographic coupling research',\n",
       " 'Amsler measure',\n",
       " 'author co citation study',\n",
       " 'co citation graph',\n",
       " 'co citation review',\n",
       " 'citation proximity',\n",
       " 'bibliographically coupled',\n",
       " 'bibliometric research',\n",
       " 'scientometric research',\n",
       " 'statistical simulation method',\n",
       " 'Metropolis–Hastings methodology',\n",
       " 'optimization modelling',\n",
       " 'optimisation study',\n",
       " 'optimization method',\n",
       " 'linear fractional programming',\n",
       " 'constraint optimization',\n",
       " 'multicriteria decision making',\n",
       " 'multicriteria decision analysis',\n",
       " 'multi criteria decision analysis',\n",
       " 'multicriteria evaluation',\n",
       " 'vector optimisation',\n",
       " 'SIR method',\n",
       " 'information systems design methodology',\n",
       " 'technology design methodology',\n",
       " 'design science research guideline',\n",
       " 'internet artifact DSR',\n",
       " 'implementation of information system artifact',\n",
       " 'developed ICT artifact',\n",
       " 'information technology artifact implementation of',\n",
       " 'design science technology artifact',\n",
       " 'implementation of IT artefact',\n",
       " 'information technologies artefact design of',\n",
       " 'information and? communications technologies artifact',\n",
       " 'information systems artefact DSR',\n",
       " 'design of information system artefact',\n",
       " 'implementation of information technologies artefact',\n",
       " 'development ICT artifact',\n",
       " 'designed ICT artefact',\n",
       " 'information and? communications technologies artefact',\n",
       " 'ICT artifact development',\n",
       " 'development of information and? communications technology artefact',\n",
       " 'DSR digital artefact',\n",
       " 'information technologies artifact design',\n",
       " 'IT artifact design',\n",
       " 'DSR information and? communications technology artifact',\n",
       " 'developed software artefact',\n",
       " 'design science research ICT artefact',\n",
       " 'design information technology artifact',\n",
       " 'development information technology artefact',\n",
       " 'development technology artefact',\n",
       " 'described information system artefact',\n",
       " 'technologies artifact design science research',\n",
       " 'ICT artifact designed',\n",
       " 'internet artifact design science',\n",
       " 'design science information and? communications technologies artifact',\n",
       " 'instantiation',\n",
       " 'structured literature review',\n",
       " 'systematic bibliograph survey',\n",
       " 'systematic bibliograph study',\n",
       " 'systematic literature analysis',\n",
       " 'systematic bibliographical research',\n",
       " 'structured library survey',\n",
       " 'systematic library research',\n",
       " 'systematic mapping method',\n",
       " 'systematic bibliographical study',\n",
       " 'systematic bibliographic research',\n",
       " 'paper',\n",
       " 'co author analysis',\n",
       " 'co author survey',\n",
       " 'quasi Monte Carlo study',\n",
       " 'Monte Carlo research',\n",
       " 'Monte Carlo investigation',\n",
       " 'quasi Monte Carlo research',\n",
       " 'Markov chain model',\n",
       " 'Markov chain',\n",
       " 'algorithmic investigation',\n",
       " 'algorithmic technique',\n",
       " 'algorithmic model',\n",
       " 'algorithmic approach',\n",
       " 'analytical model',\n",
       " 'math modeling',\n",
       " 'design based research',\n",
       " 'design based description',\n",
       " 'design oriented study',\n",
       " 'design based methodology',\n",
       " 'implementation internet artifact',\n",
       " 'DSR software artifact',\n",
       " 'information technology artefact design science research',\n",
       " 'IS artefact development',\n",
       " 'artifact design science research',\n",
       " 'information and? communications technology artifact proposed',\n",
       " 'design of software artefact',\n",
       " 'DSR IT artefact',\n",
       " 'developed digital artifact',\n",
       " 'information and? communications technology prototyping',\n",
       " 'development information systems artefact',\n",
       " 'prototypical implementation',\n",
       " 'development of IS artifact',\n",
       " 'internet artefact designed',\n",
       " 'information systems artefact proposed',\n",
       " 'ICT artefact development of',\n",
       " 'IT artefact development of',\n",
       " 'design of technologies artefact',\n",
       " 'prototyping of artifact',\n",
       " 'information system artifact development of',\n",
       " 'proposed ICT artifact',\n",
       " 'information system artefact developed',\n",
       " 'software artefact development of',\n",
       " 'information and? communications technology artifact description',\n",
       " 'implementation software artifact',\n",
       " 'technology artefact developed',\n",
       " 'prototyping of artefact',\n",
       " 'information system artifact development',\n",
       " 'technologies artifact described',\n",
       " 'technology artifact designed',\n",
       " 'technologies artefact described',\n",
       " 'design science ICT artifact',\n",
       " 'information technology artefact proposed',\n",
       " 'technology artifact design',\n",
       " 'prototypical artefact',\n",
       " 'development of ICT artifact',\n",
       " 'information technology artifact proposed',\n",
       " 'designed information and? communications technologies artefact',\n",
       " 'information technology artifact described',\n",
       " 'information and? communications technologies artifact implementation of',\n",
       " 'information systems artifact described',\n",
       " 'development of information technologies artifact',\n",
       " 'DSR information and? communications technologies artefact',\n",
       " 'information and? communications technology artefact described',\n",
       " 'prototyping of internet',\n",
       " 'software artefact developed',\n",
       " 'development of technology artifact',\n",
       " 'proposed information systems artefact',\n",
       " 'information technology artefact description',\n",
       " 'design science research information technology artefact',\n",
       " 'software prototyping',\n",
       " 'design information and? communications technologies artefact',\n",
       " 'technologies artifact developed',\n",
       " 'information and? communications technologies artefact developed',\n",
       " 'artefact development of',\n",
       " 'development of instantiation',\n",
       " 'development software artifact',\n",
       " 'information and? communications technologies artifact implementation',\n",
       " 'information and? communications technology artefact implementation',\n",
       " 'designed information system artifact',\n",
       " 'IS artefact design of',\n",
       " 'IT artefact described',\n",
       " 'DSR IT artifact',\n",
       " 'information technology artefact design of',\n",
       " 'information systems artefact development of',\n",
       " 'internet artefact development',\n",
       " 'developed information technology artifact',\n",
       " 'information systems artifact developed',\n",
       " 'digital artefact designed',\n",
       " 'technologies artifact designed',\n",
       " 'artifact design',\n",
       " 'prototypical artifact',\n",
       " 'IT artefact',\n",
       " 'described information and? communications technology artifact',\n",
       " 'software artifact proposed',\n",
       " 'information systems artefact implementation of',\n",
       " 'described IS artifact',\n",
       " 'design science research information and? communications technologies artefact',\n",
       " 'information systems artifact implementation',\n",
       " 'information systems artefact development',\n",
       " 'design science research information systems artifact',\n",
       " 'ICT artefact',\n",
       " 'information and? communications technology artefact DSR',\n",
       " 'technologies artefact DSR',\n",
       " 'information technology artefact developed',\n",
       " 'information systems artefact design of',\n",
       " 'description technologies artifact',\n",
       " 'software artifact',\n",
       " 'design science information and? communications technology artefact',\n",
       " 'information technologies artifact development of',\n",
       " 'build theoretical modeling',\n",
       " 'generated theoretical explanation',\n",
       " 'construct theoretical modeling',\n",
       " 'proposed of theory',\n",
       " 'present theoretical modeling',\n",
       " 'developing of theory',\n",
       " 'generated theoretical modelling',\n",
       " 'develops of theory',\n",
       " 'formulating theoretical model',\n",
       " 'constructs theoretical modeling',\n",
       " 'present theoretical framework',\n",
       " 'presented theory',\n",
       " 'propose theoretical framework',\n",
       " 'generating theoretical framework',\n",
       " 'formulate of theory',\n",
       " 'developed theoretical explanation',\n",
       " 'builded theoretical explanation',\n",
       " 'formulates theory',\n",
       " 'presented of theory',\n",
       " 'constructs theoretical model',\n",
       " 'proposes theoretical explanation',\n",
       " 'generates theoretical model',\n",
       " 'theorising',\n",
       " 'theory generation',\n",
       " 'develops theoretical explanation',\n",
       " 'contribution to the theorical discussion',\n",
       " 'meta model',\n",
       " 'data modelling research',\n",
       " 'entity data modelling',\n",
       " 'information modelling',\n",
       " 'galaxy schema',\n",
       " 'E R diagram',\n",
       " 'method customization',\n",
       " 'business process modeling notation',\n",
       " 'data flow diagram',\n",
       " 'ontological design',\n",
       " 'BWW ontology',\n",
       " 'Bunge Wand Weber framework',\n",
       " 'randomized controled experimental design',\n",
       " 'randomized blind experimental',\n",
       " 'intervention blinded experimental design',\n",
       " 'computer randomized experiment',\n",
       " 'blinded clinical experimental design',\n",
       " 'intervention controled experiment',\n",
       " 'artificial placebo experimental design',\n",
       " 'randomised blind experiment',\n",
       " 'intervention artificial experimental',\n",
       " 'double blind randomized experiment',\n",
       " 'computer comparative experimental design',\n",
       " 'sequential random experiment',\n",
       " 'randomized double experimental',\n",
       " 'intervention computer experiment',\n",
       " 'double blind placebo experimental design',\n",
       " 'controlled placebo experimental design',\n",
       " 'clinical numerical experimental design',\n",
       " 'computer controled trial',\n",
       " 'blinded random experiment',\n",
       " 'control controled experimental',\n",
       " 'sequential double trial',\n",
       " 'clinical controled trial',\n",
       " 'randomised computer experimental',\n",
       " 'double random experimental',\n",
       " 'clinical placebo trial',\n",
       " 'randomised intervention trial',\n",
       " 'sequential controled trial',\n",
       " 'sequential randomised experiment',\n",
       " 'intervention placebo experimental',\n",
       " 'double blind double trial',\n",
       " 'blind sequential experimental design',\n",
       " 'clinical placebo experimental',\n",
       " 'numerical intervention experiment',\n",
       " 'blind blind trial',\n",
       " 'blinded randomised experiment',\n",
       " 'intervention control experimental',\n",
       " 'computer control trial',\n",
       " 'blinded intervention experimental',\n",
       " 'double controlled experimental',\n",
       " 'random comparative experimental design',\n",
       " 'blind intervention trial',\n",
       " 'placebo trial',\n",
       " 'double blind random experimental design',\n",
       " 'numerical randomized experimental design',\n",
       " 'placebo random trial',\n",
       " 'controled controlled experimental design',\n",
       " 'controled placebo trial',\n",
       " 'controlled comparative experimental design',\n",
       " 'blinded artificial experimental design',\n",
       " 'computer computer trial',\n",
       " 'random placebo experimental design',\n",
       " 'blinded comparative experimental design',\n",
       " 'blind comparative experimental',\n",
       " 'placebo blinded trial',\n",
       " 'controled artificial trial',\n",
       " 'artificial comparative trial',\n",
       " 'controlled blinded experimental',\n",
       " 'clinical sequential experimental design',\n",
       " 'controlled random experiment',\n",
       " 'double placebo experimental design',\n",
       " 'control controlled experimental design',\n",
       " 'random randomized experimental',\n",
       " 'random double blind experiment',\n",
       " 'randomized double blind experimental design',\n",
       " 'artificial comparative experiment',\n",
       " 'control controled trial',\n",
       " 'numerical clinical experimental design',\n",
       " 'controled control experimental design',\n",
       " 'randomised sequential experimental',\n",
       " 'random computer trial',\n",
       " 'blinded artificial experimental',\n",
       " 'blind controlled experiment',\n",
       " 'random clinical trial',\n",
       " 'placebo artificial experimental design',\n",
       " 'computer randomised experiment',\n",
       " 'computer double blind trial',\n",
       " 'double randomised experimental',\n",
       " 'controled double blind experimental',\n",
       " 'blinded intervention experimental design',\n",
       " 'placebo randomized experiment',\n",
       " 'random control experiment',\n",
       " 'numerical controlled experimental design',\n",
       " 'random double experimental design',\n",
       " 'comparative experiment',\n",
       " 'control computer experiment',\n",
       " 'random artificial experiment',\n",
       " 'random placebo trial',\n",
       " 'controled double experimental design',\n",
       " 'placebo blind trial',\n",
       " 'clinical blind experimental design',\n",
       " 'control sequential experimental design',\n",
       " 'blind controled experimental design',\n",
       " 'control intervention experimental',\n",
       " 'placebo intervention experimental design',\n",
       " 'double intervention experimental',\n",
       " 'numerical blind trial',\n",
       " 'numerical numerical experimental design',\n",
       " 'randomised double blind experimental',\n",
       " 'randomised controled experiment',\n",
       " 'randomised placebo experimental',\n",
       " 'placebo random experiment',\n",
       " 'control intervention experiment',\n",
       " 'intervention study',\n",
       " 'computer artificial experimental',\n",
       " 'placebo computer trial',\n",
       " 'numerical randomised trial',\n",
       " 'numerical numerical experimental',\n",
       " 'randomized double blind experimental',\n",
       " 'control randomized experiment',\n",
       " 'random randomised trial',\n",
       " 'clinical randomized trial',\n",
       " 'numerical controled experimental design',\n",
       " 'double blind clinical experimental design',\n",
       " 'randomised blinded experimental',\n",
       " 'artificial randomised experiment',\n",
       " 'sequential experimental',\n",
       " 'blinded blind experimental',\n",
       " 'randomised controled experimental',\n",
       " 'numerical computer trial',\n",
       " 'numerical experiment',\n",
       " 'random random trial',\n",
       " 'computer experiment',\n",
       " 'placebo control trial',\n",
       " 'controled blinded experimental',\n",
       " 'numerical random experiment',\n",
       " 'blind computer experimental design',\n",
       " 'numerical controled trial',\n",
       " 'randomised intervention experimental design',\n",
       " 'computer double blind experiment',\n",
       " 'randomized randomized experiment',\n",
       " 'computer blinded experimental',\n",
       " 'double blind computer experimental',\n",
       " 'blind computer experimental',\n",
       " 'randomized randomised experimental',\n",
       " 'sequential experimental design',\n",
       " 'double randomized experimental design',\n",
       " 'random random experimental design',\n",
       " 'control controled experiment',\n",
       " 'controlled trial',\n",
       " 'double randomised experimental design',\n",
       " 'sequential sequential trial',\n",
       " 'placebo control experimental design',\n",
       " 'laboratory blinded experimental',\n",
       " 'laboratory double blind methodology',\n",
       " 'double blind laboratory trial',\n",
       " 'controled lab approach',\n",
       " 'blinded laboratory study',\n",
       " 'blind laboratory experimental',\n",
       " 'laboratory blinded experimental design',\n",
       " 'double blind laboratory study',\n",
       " 'laboratory control technique',\n",
       " 'intervention lab methodology',\n",
       " 'double blind lab experimental design',\n",
       " 'double laboratory methodology',\n",
       " 'blinded lab analysis',\n",
       " 'lab experimental design',\n",
       " 'computer laboratory investigation',\n",
       " 'random laboratory analysis',\n",
       " 'laboratory blinded analysis',\n",
       " 'randomized laboratory study',\n",
       " 'laboratory blinded description',\n",
       " 'laboratory blind investigation',\n",
       " 'randomized controlled clinical experimental design',\n",
       " 'placebo lab methodology',\n",
       " 'controlled lab experimental design',\n",
       " 'blind lab research',\n",
       " 'longitudinal trial',\n",
       " 'cross sectional experimental analysis',\n",
       " 'blind experimental design design',\n",
       " 'placebo experimental design design',\n",
       " 'clinical experimental design design',\n",
       " 'blinded trial design',\n",
       " 'sequential experiment design',\n",
       " 'double blind trial design',\n",
       " 'statistical experimental design',\n",
       " 'controlled experimental design design',\n",
       " 'randomized experiment design',\n",
       " 'controled experimental design design',\n",
       " 'factorial design',\n",
       " 'Plackett Burman design',\n",
       " 'web based quantitative polling method',\n",
       " 'telephone based supervised questionnaire analysis',\n",
       " 'quantitative based online survey research',\n",
       " 'opinion based non survey approach',\n",
       " 'non based supervised poll research',\n",
       " 'supervised based poll methodology',\n",
       " 'web based poll description',\n",
       " 'consumer based quantitative questionnaire methodology',\n",
       " 'supervised based opinion survey approach',\n",
       " 'embedded based sample polling approach',\n",
       " 'paper online questioning',\n",
       " 'quantitative based web survey technique',\n",
       " 'paper based preliminary questioning investigation',\n",
       " 'preliminary based postal poll description',\n",
       " 'sample based face questioning technique',\n",
       " 'face based embedded questioning analysis',\n",
       " 'telephone based web questionnaire research',\n",
       " 'standardized based face polling method',\n",
       " 'supervised consumer poll',\n",
       " 'web based preliminary questioning methodology',\n",
       " 'supervised based face questioning research',\n",
       " 'email non survey',\n",
       " 'attached based online polling',\n",
       " 'standardized based opinion polling approach',\n",
       " 'standardized based supervised questioning method',\n",
       " 'supervised based embedded survey description',\n",
       " 'embedded based telephone questioning method',\n",
       " 'consumer based quantitative questionnaire technique',\n",
       " 'preliminary based online survey',\n",
       " 'sample based quantitative questionnaire description',\n",
       " 'non based telephone polling approach',\n",
       " 'supervised based non poll method',\n",
       " 'attached non poll',\n",
       " 'preliminary based poll analysis',\n",
       " 'telephone based non questionnaire research',\n",
       " 'consumer based online polling study',\n",
       " 'opinion based non polling methodology',\n",
       " 'preliminary based non questionnaire investigation',\n",
       " 'face online questionnaire',\n",
       " 'telephone based embedded poll investigation',\n",
       " 'face email survey',\n",
       " 'quantitative based sample questioning analysis',\n",
       " 'web based email polling description',\n",
       " 'email online questionnaire',\n",
       " 'non based face polling analysis',\n",
       " 'embedded based preliminary polling study',\n",
       " 'supervised based supervised polling approach',\n",
       " 'embedded based embedded polling analysis',\n",
       " 'mail based paper polling methodology',\n",
       " 'sample based quantitative questioning study',\n",
       " 'polling description',\n",
       " 'mail based face polling description',\n",
       " 'sample preliminary questioning',\n",
       " 'non based postal polling investigation',\n",
       " 'postal embedded poll',\n",
       " 'attached based email poll',\n",
       " 'supervised based telephone questionnaire analysis',\n",
       " 'embedded based mail survey research',\n",
       " 'non based face questionnaire technique',\n",
       " 'opinion based supervised questioning method',\n",
       " 'consumer based attached questionnaire technique',\n",
       " 'face opinion polling',\n",
       " 'supervised based quantitative questioning methodology',\n",
       " 'embedded based standardized polling technique',\n",
       " 'attached based email questioning description',\n",
       " 'online based face survey research',\n",
       " 'mail based face polling',\n",
       " 'quantitative based online questioning',\n",
       " 'supervised based attached polling investigation',\n",
       " 'online based standardized poll approach',\n",
       " 'paper based standardized poll description',\n",
       " 'supervised based non poll technique',\n",
       " 'standardized based face questionnaire research',\n",
       " 'web based postal questioning technique',\n",
       " 'non based standardized poll study',\n",
       " 'preliminary based postal questionnaire study',\n",
       " 'standardized based consumer polling research',\n",
       " 'embedded based mail questioning study',\n",
       " 'opinion based consumer polling investigation',\n",
       " 'email based online questionnaire description',\n",
       " 'online based postal questionnaire investigation',\n",
       " 'consumer supervised polling',\n",
       " 'mail based sample survey study',\n",
       " 'paper based survey study',\n",
       " 'opinion based standardized polling technique',\n",
       " 'non based postal questionnaire',\n",
       " 'attached based face questionnaire investigation',\n",
       " 'sample based paper survey',\n",
       " 'embedded based questioning analysis',\n",
       " 'standardized based paper poll study',\n",
       " 'telephone based email questionnaire analysis',\n",
       " 'non based opinion questioning',\n",
       " 'embedded based survey method',\n",
       " 'web based postal questioning study',\n",
       " 'embedded based preliminary questionnaire',\n",
       " 'standardized based telephone survey description',\n",
       " 'paper based telephone poll',\n",
       " 'supervised based mail polling description',\n",
       " 'supervised based preliminary poll',\n",
       " 'non based survey approach',\n",
       " 'telephone based online questioning method',\n",
       " 'standardized based mail survey',\n",
       " 'supervised embedded poll',\n",
       " 'supervised based standardized poll description',\n",
       " 'opinion based attached questioning methodology',\n",
       " 'face postal questionnaire',\n",
       " 'opinion based attached polling',\n",
       " 'online based paper poll analysis',\n",
       " 'attached based consumer questionnaire study',\n",
       " 'consumer based web survey analysis',\n",
       " 'online based non questioning study',\n",
       " 'quantitative based web questionnaire methodology',\n",
       " 'paper based preliminary questionnaire analysis',\n",
       " 'embedded based supervised questionnaire methodology',\n",
       " 'embedded based attached poll technique',\n",
       " 'sample based standardized polling investigation',\n",
       " 'quantitative based survey technique',\n",
       " 'sample based paper polling methodology',\n",
       " 'quantitative based non questioning methodology',\n",
       " 'online based email poll',\n",
       " 'web based preliminary questionnaire analysis',\n",
       " 'opinion based standardized poll investigation',\n",
       " 'standardized based sample poll method',\n",
       " 'opinion based non questionnaire research',\n",
       " 'quantitative based telephone survey technique',\n",
       " 'embedded based attached polling approach',\n",
       " 'supervised based non questioning analysis',\n",
       " 'mail based opinion survey research',\n",
       " 'consumer based supervised poll technique',\n",
       " 'embedded based online questioning study',\n",
       " 'consumer based questioning study',\n",
       " 'non based online polling method',\n",
       " 'paper based web polling investigation',\n",
       " 'paper based sample poll method',\n",
       " 'consumer based face questionnaire technique',\n",
       " 'consumer based survey methodology',\n",
       " 'supervised based paper questioning study',\n",
       " 'quantitative based postal questionnaire approach',\n",
       " 'consumer based sample questionnaire technique',\n",
       " 'opinion based telephone poll technique',\n",
       " 'postal based non questioning analysis',\n",
       " 'attached based non questioning study',\n",
       " 'preliminary based email questionnaire',\n",
       " 'online based face poll research',\n",
       " 'consumer based email polling',\n",
       " 'embedded based email questionnaire methodology',\n",
       " 'web based standardized questionnaire analysis',\n",
       " 'non based online polling description',\n",
       " 'embedded based standardized polling research',\n",
       " 'sample based embedded questionnaire study',\n",
       " 'attached based postal survey analysis',\n",
       " 'web opinion questioning',\n",
       " 'email based supervised poll methodology',\n",
       " 'paper based standardized questioning analysis',\n",
       " 'postal based consumer survey approach',\n",
       " 'quantitative based mail polling study',\n",
       " 'preliminary based quantitative survey',\n",
       " 'postal based mail questionnaire methodology',\n",
       " 'preliminary embedded polling',\n",
       " 'opinion based online polling investigation',\n",
       " 'email based sample questioning investigation',\n",
       " 'preliminary based standardized questionnaire',\n",
       " 'preliminary based supervised polling analysis',\n",
       " 'face based non poll technique',\n",
       " 'postal based preliminary questionnaire approach',\n",
       " 'email postal questionnaire',\n",
       " 'embedded based sample questionnaire methodology',\n",
       " 'embedded based opinion survey study',\n",
       " 'preliminary based opinion polling approach',\n",
       " 'postal based quantitative poll description',\n",
       " 'preliminary based opinion questionnaire description',\n",
       " 'telephone based mail survey',\n",
       " 'online based postal questioning research',\n",
       " 'mail based supervised questionnaire analysis',\n",
       " 'email based consumer questioning',\n",
       " 'consumer based face survey research',\n",
       " 'preliminary based face poll description',\n",
       " 'attached based opinion questionnaire technique',\n",
       " 'consumer based questionnaire study',\n",
       " 'standardized based paper poll approach',\n",
       " 'preliminary based face poll',\n",
       " 'telephone based attached polling technique',\n",
       " 'face face questionnaire',\n",
       " 'telephone based email poll approach',\n",
       " 'standardized based quantitative survey investigation',\n",
       " 'mail based quantitative polling study',\n",
       " 'sample based consumer questionnaire analysis',\n",
       " 'consumer based opinion survey technique',\n",
       " 'consumer based face polling methodology',\n",
       " 'supervised based postal survey investigation',\n",
       " 'postal supervised poll',\n",
       " 'mail based paper questionnaire approach',\n",
       " 'non based supervised survey analysis',\n",
       " 'embedded based postal questionnaire methodology',\n",
       " 'mail based face poll investigation',\n",
       " 'randomized lab experimental design',\n",
       " 'placebo laboratory experimental design',\n",
       " 'random lab experimental',\n",
       " 'randomised laboratory study',\n",
       " 'blind lab experimental design',\n",
       " 'lab methodology',\n",
       " 'laboratory blinded investigation',\n",
       " 'controlled lab technique',\n",
       " 'double blind lab technique',\n",
       " 'clinical laboratory study',\n",
       " 'sequential lab trial',\n",
       " 'laboratory sequential experiment',\n",
       " 'intervention lab study',\n",
       " 'blinded laboratory analysis',\n",
       " 'double lab research',\n",
       " 'clinical laboratory analysis',\n",
       " 'clinical lab trial',\n",
       " 'randomised lab investigation',\n",
       " 'controled laboratory experimental',\n",
       " 'lab technique',\n",
       " 'control lab investigation',\n",
       " 'laboratory computer description',\n",
       " 'laboratory double blind research',\n",
       " 'laboratory randomised approach',\n",
       " 'laboratory clinical method',\n",
       " 'artificial laboratory method',\n",
       " 'laboratory controled technique',\n",
       " 'laboratory computer study',\n",
       " 'clinical laboratory trial',\n",
       " 'randomized lab method',\n",
       " 'laboratory blinded research',\n",
       " 'random lab analysis',\n",
       " 'laboratory randomized approach',\n",
       " 'random lab approach',\n",
       " 'laboratory blinded method',\n",
       " 'random laboratory investigation',\n",
       " 'control lab trial',\n",
       " 'clinical lab experimental design',\n",
       " 'controled lab method',\n",
       " 'laboratory controled approach',\n",
       " 'controled lab technique',\n",
       " 'numerical lab approach',\n",
       " 'random laboratory methodology',\n",
       " 'laboratory experimental design',\n",
       " 'clinical lab methodology',\n",
       " 'double laboratory experimental design',\n",
       " 'double blind laboratory experimental',\n",
       " 'controled laboratory description',\n",
       " 'double blind laboratory investigation',\n",
       " 'laboratory blinded study',\n",
       " 'double lab approach',\n",
       " 'blinded laboratory research',\n",
       " 'laboratory placebo investigation',\n",
       " 'laboratory controled experimental',\n",
       " 'quantitative based supervised questioning investigation',\n",
       " 'sample based mail polling approach',\n",
       " 'consumer based attached poll study',\n",
       " 'standardized based mail polling technique',\n",
       " 'standardized based non poll',\n",
       " 'embedded based quantitative questionnaire research',\n",
       " 'preliminary based embedded survey analysis',\n",
       " 'preliminary based preliminary survey analysis',\n",
       " 'embedded based standardized questioning technique',\n",
       " 'sample based email poll description',\n",
       " 'face based attached survey technique',\n",
       " 'supervised opinion poll',\n",
       " 'sample based consumer questionnaire investigation',\n",
       " 'opinion based supervised questionnaire description',\n",
       " 'consumer based embedded polling analysis',\n",
       " 'embedded based preliminary questioning methodology',\n",
       " 'paper based quantitative questionnaire methodology',\n",
       " 'attached based telephone questioning analysis',\n",
       " 'non non questionnaire',\n",
       " 'supervised based consumer polling investigation',\n",
       " 'consumer based non survey approach',\n",
       " 'face based preliminary poll approach',\n",
       " 'opinion based postal polling methodology',\n",
       " 'postal based web questioning technique',\n",
       " 'mail based questionnaire investigation',\n",
       " 'postal based face questioning study',\n",
       " 'supervised based attached poll research',\n",
       " 'embedded mail questioning',\n",
       " 'sample based web survey description',\n",
       " 'face based mail polling investigation',\n",
       " 'supervised based face questioning technique',\n",
       " 'quantitative opinion questioning',\n",
       " 'sample based quantitative survey',\n",
       " 'supervised based attached poll technique',\n",
       " 'embedded based questioning study',\n",
       " 'standardized based mail questioning research',\n",
       " 'non based telephone survey analysis',\n",
       " 'email based web polling technique',\n",
       " 'supervised face questioning',\n",
       " 'attached based attached polling research',\n",
       " 'postal based sample survey study',\n",
       " 'non based quantitative survey study',\n",
       " 'preliminary based postal survey analysis',\n",
       " 'consumer based preliminary survey approach',\n",
       " 'email based paper polling technique',\n",
       " 'mail based standardized questioning methodology',\n",
       " 'email based embedded poll research',\n",
       " 'mail based preliminary polling investigation',\n",
       " 'mail based supervised polling',\n",
       " 'mail based supervised poll method',\n",
       " 'email based consumer survey research',\n",
       " 'mail based questionnaire technique',\n",
       " 'standardized embedded questioning',\n",
       " 'preliminary based preliminary questioning analysis',\n",
       " 'non based online survey approach',\n",
       " 'preliminary based online polling technique',\n",
       " 'web based quantitative polling research',\n",
       " 'preliminary based embedded polling study',\n",
       " 'paper based non questioning technique',\n",
       " 'web based non questionnaire research',\n",
       " 'embedded based face poll analysis',\n",
       " 'online based supervised questioning study',\n",
       " 'online based telephone questioning methodology',\n",
       " 'postal based online survey research',\n",
       " 'consumer based web poll technique',\n",
       " 'online based mail survey methodology',\n",
       " 'postal based non questioning method',\n",
       " 'non based questioning technique',\n",
       " 'non based email questionnaire investigation',\n",
       " 'mail based preliminary survey',\n",
       " 'postal based questioning methodology',\n",
       " 'postal based online survey technique',\n",
       " 'mail embedded polling',\n",
       " 'opinion based postal questioning methodology',\n",
       " 'telephone attached questionnaire',\n",
       " 'paper based mail questionnaire analysis',\n",
       " 'preliminary based online poll description',\n",
       " 'consumer based mail poll description',\n",
       " 'consumer based opinion survey',\n",
       " 'quantitative based quantitative polling methodology',\n",
       " 'standardized based mail polling investigation',\n",
       " 'non based non survey technique',\n",
       " 'quantitative based supervised poll methodology',\n",
       " 'telephone based telephone poll',\n",
       " 'postal based non poll analysis',\n",
       " 'consumer based standardized questionnaire study',\n",
       " 'standardized face survey',\n",
       " 'non based preliminary survey study',\n",
       " 'preliminary based quantitative polling research',\n",
       " 'postal based consumer poll method',\n",
       " 'telephone based consumer survey analysis',\n",
       " 'preliminary based postal poll approach',\n",
       " 'web embedded questionnaire',\n",
       " 'embedded quantitative questioning',\n",
       " 'standardized based embedded survey analysis',\n",
       " 'paper based embedded poll analysis',\n",
       " 'preliminary based standardized questioning investigation',\n",
       " 'face based telephone polling investigation',\n",
       " 'opinion based opinion survey study',\n",
       " 'web based standardized questionnaire study',\n",
       " 'mail based supervised questionnaire research',\n",
       " 'paper based preliminary survey investigation',\n",
       " 'email based opinion poll approach',\n",
       " 'consumer based questionnaire',\n",
       " 'paper based web questionnaire research',\n",
       " 'quantitative based sample polling analysis',\n",
       " 'telephone based opinion poll technique',\n",
       " 'face based non questioning method',\n",
       " 'email based standardized polling study',\n",
       " 'embedded based face survey',\n",
       " 'standardized supervised questionnaire',\n",
       " 'online based mail survey analysis',\n",
       " 'email based web survey',\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_synonyms_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['methodological entity',\n",
       " 'research method',\n",
       " 'conceptual method',\n",
       " 'literature study',\n",
       " 'structured literature research',\n",
       " 'literature sample',\n",
       " 'bibliometric software',\n",
       " 'literature database',\n",
       " 'Web of Science Core Collection',\n",
       " 'academic journal list',\n",
       " 'individual IS journal',\n",
       " 'bibliometric analysis',\n",
       " 'simulation',\n",
       " 'stochastic simulation',\n",
       " 'Monte Carlo simulation',\n",
       " 'Markov chain Monte Carlo',\n",
       " 'computational algorithm',\n",
       " 'mathematical model',\n",
       " 'economic model',\n",
       " 'stochastic model',\n",
       " 'Markov model',\n",
       " 'optimization model',\n",
       " 'discrete optimization',\n",
       " 'integer programming',\n",
       " 'integer linear programming',\n",
       " 'combinatorial optimization',\n",
       " 'traveling purchaser problem',\n",
       " 'multiple criteria decision making',\n",
       " 'multi objective optimization',\n",
       " 'design science',\n",
       " 'design methodology',\n",
       " 'design process',\n",
       " 'conceptual modelling',\n",
       " 'maturity model',\n",
       " 'capability maturity model',\n",
       " 'data modeling',\n",
       " 'database modeling',\n",
       " 'method engineering',\n",
       " 'business process modeling',\n",
       " 'business process modeling language',\n",
       " 'advanced case management',\n",
       " 'modeling language',\n",
       " 'unified modeling language',\n",
       " 'ontological modelling',\n",
       " 'existing ontologies',\n",
       " 'data collection method',\n",
       " 'empirical quantitative method',\n",
       " 'experiment',\n",
       " 'field experiment',\n",
       " 'experimental design',\n",
       " 'screening design',\n",
       " 'survey',\n",
       " 'survey design',\n",
       " 'psychometrics',\n",
       " 'survey design problem',\n",
       " 'biometric measurement',\n",
       " 'neurophysiology',\n",
       " 'functional neuroimaging',\n",
       " 'magnetic resonance imaging',\n",
       " 'brain stimulation',\n",
       " 'oculometry',\n",
       " 'electrodermal activity',\n",
       " 'quantitative observational study',\n",
       " 'quasi experiment',\n",
       " 'case control study',\n",
       " 'self quantification',\n",
       " 'digital observation',\n",
       " 'digital trace data',\n",
       " 'product review',\n",
       " 'process trace data',\n",
       " 'empirical qualitative method',\n",
       " 'case study',\n",
       " 'action research',\n",
       " 'design science evaluation',\n",
       " 'expert evaluation',\n",
       " 'usability testing',\n",
       " 'qualitativ observational study',\n",
       " 'ethnography',\n",
       " 'visual ethnography',\n",
       " 'archival research',\n",
       " 'company material',\n",
       " 'public company material',\n",
       " 'archival database',\n",
       " 'biographical database',\n",
       " 'financial archival database',\n",
       " 'news archival database',\n",
       " 'qualitative interview',\n",
       " 'personal interview',\n",
       " 'group interview',\n",
       " 'nominal group technique',\n",
       " 'time horizon of research',\n",
       " 'longitudinal research',\n",
       " 'data analysis method',\n",
       " 'qualitative analysis',\n",
       " 'QDA software',\n",
       " 'configurational comparative method',\n",
       " 'qualitative content analysis',\n",
       " 'narrative analysis',\n",
       " 'critical narrative approach',\n",
       " 'qualitative comparative analysis',\n",
       " 'quantitative analysis',\n",
       " 'quantitative analysis tool',\n",
       " 'Wolfram Research',\n",
       " 'machine learning',\n",
       " 'machine learning method',\n",
       " 'deep learning',\n",
       " 'recurrent neural network',\n",
       " 'generative adversarial network',\n",
       " 'transformer model',\n",
       " 'language model',\n",
       " 'generative pre-trained transformer',\n",
       " 'text-to-image model',\n",
       " 'DALL-E',\n",
       " 'text-to-3d model',\n",
       " 'word embedding',\n",
       " 'deep learning tool',\n",
       " 'supervised learning',\n",
       " 'classification method',\n",
       " 'meta learning',\n",
       " 'ensemble learning',\n",
       " 'bagging method',\n",
       " 'boosting method',\n",
       " 'gradient boosting',\n",
       " 'unsupervised learning',\n",
       " 'cluster analysis',\n",
       " 'partitional clustering',\n",
       " 'hierarchical clustering',\n",
       " 'agglomerative hierarchical clustering',\n",
       " 'density based clusting',\n",
       " 'anomaly detection',\n",
       " 'outlier test',\n",
       " 'self-supervised learning',\n",
       " 'machine learning process',\n",
       " 'privacy preserving machine learning',\n",
       " 'machine learning application',\n",
       " 'image processing',\n",
       " 'image data source',\n",
       " 'computer vision tool',\n",
       " 'natural language processing',\n",
       " 'NLP method',\n",
       " 'latent semantic indexing',\n",
       " 'topic model',\n",
       " 'NLP tool',\n",
       " 'NLP application',\n",
       " 'sentiment analysis',\n",
       " 'document weighting factor',\n",
       " 'spatial analysis',\n",
       " 'initial data analysis',\n",
       " 'data transformation',\n",
       " 'data imputation',\n",
       " 'normalization data transformation',\n",
       " 'descriptive statistic',\n",
       " 'analysis of conditional distribution',\n",
       " 'probabilistic graphical model',\n",
       " 'path analysis',\n",
       " 'latent variable model',\n",
       " 'latent class analysis',\n",
       " 'structural equation modeling',\n",
       " 'partial least squares path modeling',\n",
       " 'graph analysis',\n",
       " 'network analysis',\n",
       " 'social network analysis',\n",
       " 'link analysis',\n",
       " 'trade-off analysis method',\n",
       " 'post analysis',\n",
       " 'time series analysis',\n",
       " 'autocorrelation analysis',\n",
       " 'autoregressive integrated moving average',\n",
       " 'Dickey-Fuller-test',\n",
       " 'causality analysis',\n",
       " 'propensity score method',\n",
       " 'survival analysis',\n",
       " 'survival function',\n",
       " 'hazard function',\n",
       " 'sequential analysis',\n",
       " 'multivariate statistics',\n",
       " 'dimensionality reduction',\n",
       " 'factor analysis',\n",
       " 'discriminant analysis',\n",
       " 'regression analysis method',\n",
       " 'partial least squares regression',\n",
       " 'partial least squares discriminant analysis',\n",
       " 'nonlinear regression analysis',\n",
       " 'regularization-based regression',\n",
       " 'robust regression',\n",
       " 'linear regression analysis',\n",
       " 'linear regression estimation method',\n",
       " 'generalized linear model',\n",
       " 'general multivariate regression model',\n",
       " 'probit regression',\n",
       " 'logistic regression',\n",
       " 'regression diagnostic',\n",
       " 'structural break test',\n",
       " 'correlation of model error',\n",
       " 'distribution of model error',\n",
       " 'specification error test',\n",
       " 'hierarchical linear modeling',\n",
       " 'generalizability analysis',\n",
       " 'G theory tool',\n",
       " 'statistical hypothesis test',\n",
       " 'location test',\n",
       " 'sample of location test',\n",
       " 'parametricity of location test',\n",
       " 'pairing of location test',\n",
       " 'level of measurement of location test',\n",
       " \"Student's t-test\",\n",
       " 'goodness of fit statistical test',\n",
       " 'chi squared test',\n",
       " \"Pearson's chi-squared test\",\n",
       " 'between group comparison statistical test',\n",
       " 'ANOVA',\n",
       " 'non-parametric between group comparison test',\n",
       " 'post-hoc analysis',\n",
       " 'test of association between categorical variables',\n",
       " \"Pearson's Chi square test\",\n",
       " 'statistical test assumption',\n",
       " 'homoskedasticity test',\n",
       " 'odds ratio homogeneity test',\n",
       " 'questionable research practice',\n",
       " 'data dredging']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ontology_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No embeddings found for the new term: apple\n",
      "'integer programming' is synonym to 'programming' with a similarity score of 1.00\n",
      "'discrete optimization' is synonym to 'optimization' with a similarity score of 1.00\n",
      "'questionable research practice' is synonym to 'practice' with a similarity score of 1.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Combine both lists to create a corpus\n",
    "combined_data = data_synonyms_list + data_ontology_list\n",
    "\n",
    "# Tokenize the text (simple whitespace tokenization)\n",
    "tokenized_data = [text.split() for text in combined_data]\n",
    "\n",
    "# Train the Word2Vec model\n",
    "model = Word2Vec(tokenized_data, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Get vectors for each word in data_synonyms_list and data_ontology_list\n",
    "embeddings_synonyms = {word: model.wv[word] for text in data_synonyms_list for word in text.split()}\n",
    "embeddings_ontology = {word: model.wv[word] for text in data_ontology_list for word in text.split()}\n",
    "\n",
    "# Define the get_embeddings function\n",
    "def get_embeddings(term):\n",
    "    tokens = term.split()\n",
    "    embeddings = {}\n",
    "    for token in tokens:\n",
    "        if token in model.wv:\n",
    "            embeddings[token] = model.wv[token]\n",
    "    return embeddings\n",
    "\n",
    "# Define the is_synonym function\n",
    "def is_synonym(new_term):\n",
    "    \"\"\"\n",
    "    Compare a new_term with the list of synonyms and ontology terms stored using cosine similarity.\n",
    "\n",
    "    Args:\n",
    "        new_term: a single term to be compared\n",
    "    \n",
    "    Returns:\n",
    "        A string that tells if the term is a synonym to x word and the score or if there was not a synonym in the list\n",
    "    \"\"\"\n",
    "    new_term_embds = get_embeddings(new_term)\n",
    "    if not new_term_embds:\n",
    "        return f\"No embeddings found for the new term: {new_term}\"\n",
    "\n",
    "    similarity_scores = {}\n",
    "    overall_embeddings = {**embeddings_synonyms, **embeddings_ontology}\n",
    "    \n",
    "    for term, embedding in overall_embeddings.items():\n",
    "        for new_term_token, new_term_embedding in new_term_embds.items():\n",
    "            similarity = cosine_similarity(new_term_embedding.reshape(1, -1), embedding.reshape(1, -1))[0][0]\n",
    "            similarity_scores[term] = similarity\n",
    "    \n",
    "    sorted_similarity_scores = dict(sorted(similarity_scores.items(), key=lambda item: item[1], reverse=True))\n",
    "    \n",
    "    if sorted_similarity_scores and list(sorted_similarity_scores.values())[0] > 0.7:\n",
    "        top_synonym = list(sorted_similarity_scores.keys())[0]\n",
    "        return f\"'{new_term}' is synonym to '{top_synonym}' with a similarity score of {list(sorted_similarity_scores.values())[0]:.2f}\"\n",
    "    else:\n",
    "        return f\"No close synonyms found in the list for the term: {new_term}\"\n",
    "\n",
    "# Example usage\n",
    "print(is_synonym(\"apple\"))\n",
    "print(is_synonym(\"integer programming\"))\n",
    "print(is_synonym(\"discrete optimization\"))\n",
    "print(is_synonym(\"questionable research practice\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = data_synonyms_list + data_ontology_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = [text.split() for text in combined_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'research': [ 0.09319612 -0.08419403  0.40410915  0.11716118 -0.1370745  -0.24179965\n",
      "  0.17730439  0.34169167  0.14157328 -0.4206886   0.14863181 -0.37313494\n",
      "  0.17654973 -0.07061384  0.06729862 -0.16613318  0.03670017 -0.22738826\n",
      " -0.03036536 -0.6239756  -0.03152496  0.43196243  0.1667981  -0.04803292\n",
      " -0.17558493  0.13238981 -0.4719396  -0.10090797 -0.05838131  0.05471925\n",
      " -0.16750416 -0.14575857  0.39902765  0.1593343  -0.30448285  0.2424973\n",
      "  0.03066631 -0.02267972 -0.29449704 -0.16376093  0.02703498 -0.22639926\n",
      " -0.02312569  0.30129087  0.07635976 -0.46758378 -0.15677613 -0.27619848\n",
      "  0.04277194  0.261812   -0.3688721  -0.25070834  0.43569505  0.00415363\n",
      "  0.13761587  0.00616774  0.03904133 -0.23057954  0.24122216  0.02288042\n",
      " -0.3582873  -0.23690954  0.39606732  0.2394026  -0.44352555  0.5966573\n",
      " -0.5458234   0.117043   -0.13415045 -0.15954468  0.23216367  0.43381035\n",
      "  0.317684    0.02109584  0.22612023  0.12648651  0.49473417 -0.32439283\n",
      " -0.20937142 -0.19280468 -0.31494004  0.0954963  -0.12066346  0.28323427\n",
      "  0.02662952  0.1589894   0.14916924 -0.24650256 -0.01575733  0.40820676\n",
      "  0.24787685  0.05889632 -0.08409742  0.11607999  0.35386896  0.20297588\n",
      " -0.01507111 -0.24469773 -0.08579946 -0.06447626]\n",
      "Vector for 'audio': [-0.05640537  0.00741152 -0.07549082 -0.01651391  0.01143286 -0.04265057\n",
      "  0.01127452  0.10539686  0.00466278  0.01231683  0.01361204 -0.03470916\n",
      "  0.00044284  0.0309742  -0.01539813 -0.04873792 -0.05738257 -0.00986376\n",
      "  0.03908195 -0.03494661 -0.03735903 -0.04363754  0.0188641  -0.00600597\n",
      "  0.01011541 -0.0637643  -0.0033295  -0.08173551 -0.02482789 -0.00812471\n",
      " -0.02109172 -0.0015746   0.04093172  0.01789095  0.01267086  0.00184952\n",
      " -0.06623948 -0.0513185   0.0047578  -0.10509349  0.01679589 -0.01125938\n",
      "  0.02342843 -0.01252322  0.01823877  0.00681923  0.00442803  0.00388379\n",
      "  0.04347013  0.02747866 -0.01086516 -0.00883339  0.03534525  0.03696017\n",
      "  0.00100687  0.01428229  0.02210054 -0.01586826 -0.04193517  0.00811663\n",
      "  0.01946213  0.03109304 -0.01900518 -0.00550208 -0.05401139  0.06114906\n",
      "  0.02355578 -0.01662299 -0.05576969  0.01240149  0.02314489  0.01591444\n",
      "  0.08317688  0.00155655 -0.00320601  0.01617973 -0.0231689  -0.00988917\n",
      " -0.04377363  0.01489327 -0.00128248  0.0554302  -0.05725167  0.02979457\n",
      " -0.01236901  0.03776554 -0.00857241  0.01871087  0.04136873  0.02994386\n",
      "  0.01393127 -0.0132547  -0.09035559  0.02212085  0.0228106   0.05478949\n",
      " -0.00416406 -0.07292113 -0.01717938 -0.02156842]\n"
     ]
    }
   ],
   "source": [
    "# Train the Word2Vec model\n",
    "model = Word2Vec(tokenized_data, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Get vectors for each word in data_synonyms_list and data_ontology_list\n",
    "synonym_vectors = {word: model.wv[word] for text in data_synonyms_list for word in text.split()}\n",
    "ontology_vectors = {word: model.wv[word] for text in data_ontology_list for word in text.split()}\n",
    "\n",
    "# Example: Print vector for a specific word\n",
    "print(\"Vector for 'research':\", ontology_vectors.get('research'))\n",
    "print(\"Vector for 'audio':\", synonym_vectors.get('audio'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_synonym(new_term):\n",
    "    \"\"\"\n",
    "    Compare a new_term with the list of synonyms and ontology terms stored using cosine similarity.\n",
    "\n",
    "    Args:\n",
    "        new term: a single term to be compared\n",
    "    \n",
    "    Returns:\n",
    "        A string that tells if the term is a synonym to x word and the score or if there was not a synonym in the list\n",
    "    \"\"\"\n",
    "    \n",
    "    new_term_embds = get_embeddings(new_term)\n",
    "    similarity_scores = {}\n",
    "    overall_embeddings = embeddings_synonyms #| embeddings_ontology\n",
    "    for term, embedding in overall_embeddings.items():\n",
    "        similarity = cosine_similarity(new_term_embds[new_term[0]].reshape(1, -1), embedding.reshape(1, -1))[0][0]\n",
    "        similarity_scores[term] = similarity\n",
    "    sorted_similarity_scores = dict(sorted(similarity_scores.items(), key=lambda item: item[1], reverse=True))\n",
    "    if sorted_similarity_scores and list(sorted_similarity_scores.values())[0] > 0.7:\n",
    "        top_synonym = list(sorted_similarity_scores.keys())[0]\n",
    "        return f\"is synonym to {top_synonym} with a similarity score of {list(sorted_similarity_scores.values())[0]}\"\n",
    "    else:\n",
    "        return \"No close synonyms found in the list.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m new_term \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapple\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m \u001b[43mis_synonym\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_term\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 12\u001b[0m, in \u001b[0;36mis_synonym\u001b[0;34m(new_term)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_synonym\u001b[39m(new_term):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    Compare a new_term with the list of synonyms and ontology terms stored using cosine similarity.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m        A string that tells if the term is a synonym to x word and the score or if there was not a synonym in the list\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     new_term_embds \u001b[38;5;241m=\u001b[39m \u001b[43mget_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_term\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     similarity_scores \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     14\u001b[0m     overall_embeddings \u001b[38;5;241m=\u001b[39m embeddings_synonyms \u001b[38;5;66;03m#| embeddings_ontology\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[16], line 29\u001b[0m, in \u001b[0;36mget_embeddings\u001b[0;34m(term)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_embeddings\u001b[39m(term):\n\u001b[0;32m---> 29\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m \u001b[43mterm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m()\n\u001b[1;32m     30\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokens:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "new_term = [\"apple\"]\n",
    "is_synonym(new_term)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
